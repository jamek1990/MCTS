import cv2
import numpy as np
from PIL import Image, ExifTags
from mtcnn import MTCNN
import os
import math

def correct_orientation(image_path):
    """
    Koryguje orientację obrazu na podstawie danych EXIF.
    
    Argumenty:
        image_path (str): Ścieżka do obrazu
        
    Zwraca:
        PIL.Image: Obraz z poprawioną orientacją
    """
    try:
        img = Image.open(image_path)
        
        # Sprawdzenie czy obraz ma dane EXIF
        if hasattr(img, '_getexif') and img._getexif() is not None:
            exif = dict((ExifTags.TAGS.get(k, k), v) for k, v in img._getexif().items())
            
            # Orientacja zdjęcia zgodnie ze standardem EXIF
            if 'Orientation' in exif:
                orientation = exif['Orientation']
                
                if orientation == 2:
                    # Lustrzane odbicie poziome
                    img = img.transpose(Image.FLIP_LEFT_RIGHT)
                elif orientation == 3:
                    # Rotacja o 180 stopni
                    img = img.transpose(Image.ROTATE_180)
                elif orientation == 4:
                    # Lustrzane odbicie pionowe
                    img = img.transpose(Image.FLIP_TOP_BOTTOM)
                elif orientation == 5:
                    # Lustrzane odbicie poziome i rotacja o 90 stopni w lewo
                    img = img.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.ROTATE_90)
                elif orientation == 6:
                    # Rotacja o 90 stopni w prawo
                    img = img.transpose(Image.ROTATE_270)
                elif orientation == 7:
                    # Lustrzane odbicie poziome i rotacja o 90 stopni w prawo
                    img = img.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.ROTATE_270)
                elif orientation == 8:
                    # Rotacja o 90 stopni w lewo
                    img = img.transpose(Image.ROTATE_90)
        
        return img
    except Exception as e:
        print(f"Nie można skorygować orientacji obrazu: {str(e)}")
        return Image.open(image_path)  # Zwróć oryginalny obraz w przypadku błędu

def detect_and_correct_rotation(img_rgb, detector=None):
    """
    Wykrywa i koryguje rotację twarzy na podstawie położenia oczu.
    
    Argumenty:
        img_rgb (numpy.ndarray): Obraz w formacie RGB
        detector (MTCNN): Detektor MTCNN, jeśli None zostanie utworzony nowy
        
    Zwraca:
        tuple: (skorygowany obraz, kąt rotacji)
    """
    if detector is None:
        detector = MTCNN()
    
    # Wykryj twarze
    faces = detector.detect_faces(img_rgb)
    if not faces:
        return img_rgb, 0
    
    # Użyj największej twarzy jako odniesienia
    largest_face = max(faces, key=lambda x: x['box'][2] * x['box'][3])
    
    # Sprawdź czy keypoints zawiera oczy
    keypoints = largest_face['keypoints']
    if 'left_eye' in keypoints and 'right_eye' in keypoints:
        left_eye = keypoints['left_eye']
        right_eye = keypoints['right_eye']
        
        # Oblicz kąt między oczami
        dx = right_eye[0] - left_eye[0]
        dy = right_eye[1] - left_eye[1]
        
        # Unikaj dzielenia przez zero
        if dx == 0:
            angle = 0
        else:
            angle = math.degrees(math.atan2(dy, dx))
        
        # Jeśli kąt jest znaczący (> 5 stopni), obróć obraz
        if abs(angle) > 5:
            # Określ środek obrotu (między oczami)
            center_x = (left_eye[0] + right_eye[0]) // 2
            center_y = (left_eye[1] + right_eye[1]) // 2
            center = (center_x, center_y)
            
            # Macierz obrotu
            M = cv2.getRotationMatrix2D(center, angle, 1.0)
            
            # Obróć obraz
            height, width = img_rgb.shape[:2]
            rotated_img = cv2.warpAffine(img_rgb, M, (width, height), 
                                         flags=cv2.INTER_CUBIC, 
                                         borderMode=cv2.BORDER_REPLICATE)
            
            return rotated_img, angle
    
    # Jeśli nie można skorygować, zwróć oryginalny obraz
    return img_rgb, 0

def extract_best_face(image_path, output_dir="extracted_faces", min_size=80, correct_rot=True):
    """
    Funkcja do wycinania najlepszej jakościowo twarzy z dokumentu tożsamości.
    
    Argumenty:
        image_path (str): Ścieżka do obrazu z dokumentem
        output_dir (str): Katalog, w którym zostaną zapisane wycięte twarze
        min_size (int): Minimalny rozmiar twarzy do detekcji
        correct_rot (bool): Czy korygować rotację zdjęcia
        
    Zwraca:
        str: Ścieżka do wyciętej twarzy o najlepszej jakości lub None, jeśli nie znaleziono
    """
    # Utworzenie folderu na wycięte twarze, jeśli nie istnieje
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # Korekta orientacji zdjęcia na podstawie EXIF
    if correct_rot:
        pil_img = correct_orientation(image_path)
        # Konwersja PIL Image do numpy array dla OpenCV
        img_rgb = np.array(pil_img)
        if len(img_rgb.shape) == 2:  # Obraz jest w skali szarości
            img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_GRAY2RGB)
        elif img_rgb.shape[2] == 4:  # Obraz ma kanał alfa
            img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_RGBA2RGB)
    else:
        # Standardowe wczytanie obrazu
        img = cv2.imread(image_path)
        if img is None:
            print(f"Nie można wczytać obrazu: {image_path}")
            return None
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # Inicjalizacja detektora MTCNN
    detector = MTCNN(min_face_size=min_size)
    
    # Korekta rotacji twarzy na podstawie położenia oczu
    if correct_rot:
        img_rgb, angle = detect_and_correct_rotation(img_rgb, detector)
        if abs(angle) > 5:
            print(f"Skorygowano rotację twarzy o {angle:.2f} stopni")
    
    # Detekcja twarzy
    faces = detector.detect_faces(img_rgb)
    
    if not faces:
        print(f"Nie znaleziono twarzy w obrazie: {image_path}")
        return None
    
    # Ocena jakości każdej twarzy - zoptymalizowana dla dokumentów tożsamości
    best_face = None
    best_score = -1
    
    for face in faces:
        # Pobierz współrzędne i wymiary twarzy
        x, y, width, height = face['box']
        confidence = face['confidence']
        
        # Sprawdzenie czy współrzędne są poprawne
        if x < 0 or y < 0 or width <= 0 or height <= 0:
            continue
            
        # Zabezpieczenie przed wyjściem poza granice obrazu
        if y + height > img_rgb.shape[0] or x + width > img_rgb.shape[1]:
            # Przycinamy bounding box, aby nie wychodził poza granice
            width = min(width, img_rgb.shape[1] - x)
            height = min(height, img_rgb.shape[0] - y)
        
        # Kryteria jakości dla dokumentów tożsamości:
        # 1. Rozmiar twarzy (większy = lepszy)
        size_score = width * height
        
        # 2. Pewność detekcji
        conf_score = confidence
        
        # 3. Ocena ostrości (wyższa = ostrzejsze)
        face_img = img_rgb[y:y+height, x:x+width]
        if face_img.size == 0:  # Sprawdzenie czy wycięty fragment nie jest pusty
            continue
            
        gray_face = cv2.cvtColor(face_img, cv2.COLOR_RGB2GRAY)
        laplacian_var = cv2.Laplacian(gray_face, cv2.CV_64F).var()
        
        # 4. Symetria twarzy (ważna dla dokumentów tożsamości)
        symmetry_score = 1.0
        if 'left_eye' in face['keypoints'] and 'right_eye' in face['keypoints']:
            left_eye = face['keypoints']['left_eye']
            right_eye = face['keypoints']['right_eye']
            
            # Odległość między oczami powinna być proporcjonalna do szerokości twarzy
            eye_distance = np.sqrt((left_eye[0] - right_eye[0])**2 + (left_eye[1] - right_eye[1])**2)
            ideal_ratio = 0.4  # Idealna proporcja odległości oczu do szerokości twarzy
            actual_ratio = eye_distance / width
            
            # Ocena symetrii - im bliżej idealnej proporcji, tym lepiej
            symmetry_score = 1.0 - min(1.0, abs(ideal_ratio - actual_ratio) * 5)
        
        # Całkowita ocena jakości - dostosowana do dokumentów tożsamości
        quality_score = (
            0.3 * size_score / (img_rgb.shape[0] * img_rgb.shape[1]) +  # Znormalizowany rozmiar
            0.3 * conf_score +                                         # Pewność detekcji
            0.25 * min(1.0, laplacian_var / 500) +                     # Znormalizowana ostrość
            0.15 * symmetry_score                                      # Symetria twarzy
        )
        
        # Sprawdź, czy to najlepsza twarz do tej pory
        if quality_score > best_score and width > min_size and height > min_size:
            best_score = quality_score
            best_face = {'box': face['box'], 'keypoints': face['keypoints'], 'score': quality_score}
    
    if best_face is None:
        print(f"Nie znaleziono odpowiedniej twarzy w obrazie: {image_path}")
        return None
    
    # Wytnij najlepszą twarz
    x, y, width, height = best_face['box']
    
    # Dodaj margines (15% z każdej strony - mniejszy dla dokumentów tożsamości)
    margin_x = int(width * 0.15)
    margin_y = int(height * 0.15)
    
    # Zapewnij, że wymiary nie wychodzą poza granice obrazu
    start_x = max(0, x - margin_x)
    start_y = max(0, y - margin_y)
    end_x = min(img_rgb.shape[1], x + width + margin_x)
    end_y = min(img_rgb.shape[0], y + height + margin_y)
    
    # Wycinamy twarz z oryginalnego obrazu, zachowując jakość
    face_img = img_rgb[start_y:end_y, start_x:end_x]
    pil_face = Image.fromarray(face_img)
    
    # Zapisz wyciętą twarz z zachowaniem oryginalnej jakości
    base_filename = os.path.basename(image_path)
    filename, ext = os.path.splitext(base_filename)
    output_path = os.path.join(output_dir, f"{filename}_face{ext}")
    pil_face.save(output_path, quality=100)  # Zapisujemy z najwyższą jakością
    
    print(f"Najlepsza twarz została zapisana w: {output_path}")
    print(f"Ocena jakości: {best_face['score']:.4f}")
    
    return output_path

def batch_extract_faces(input_dir, output_dir="extracted_faces", min_face_size=80, correct_rotation=True):
    """
    Przetwarza wszystkie pliki JPEG w podanym katalogu.
    
    Argumenty:
        input_dir (str): Katalog z dokumentami JPEG
        output_dir (str): Katalog do zapisania wyciętych twarzy
        min_face_size (int): Minimalny rozmiar twarzy do detekcji
        correct_rotation (bool): Czy korygować rotację zdjęcia
    """
    if not os.path.exists(input_dir):
        print(f"Katalog wejściowy nie istnieje: {input_dir}")
        return
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # Znajdź wszystkie pliki JPEG w katalogu
    image_extensions = ['.jpg', '.jpeg', '.JPG', '.JPEG']
    image_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) 
                  if os.path.isfile(os.path.join(input_dir, f)) and 
                  any(f.endswith(ext) for ext in image_extensions)]
    
    if not image_files:
        print(f"Nie znaleziono plików JPEG w katalogu: {input_dir}")
        return
    
    # Przetwarzaj każdy obraz
    results = []
    for image_path in image_files:
        print(f"Przetwarzanie obrazu: {image_path}")
        face_path = extract_best_face(image_path, output_dir, min_face_size, correct_rotation)
        if face_path:
            results.append((image_path, face_path))
    
    print(f"Zakończono przetwarzanie. Przetworzono {len(results)} z {len(image_files)} obrazów.")
    return results

# Przykład użycia
if __name__ == "__main__":
    # Dla pojedynczego dokumentu tożsamości
    # extract_best_face("ścieżka/do/dokumentu.jpg", correct_rot=True)
    
    # Dla całego katalogu z dokumentami
    # batch_extract_faces("ścieżka/do/katalogu_z_dokumentami", "ścieżka/do/katalogu_wynikowego", correct_rotation=True)
    
    # Przykładowe wywołanie
    document_path = "example_id.jpg"
    extracted_face = extract_best_face(document_path, correct_rot=True)
    
    if extracted_face:
        print(f"Pomyślnie wyekstrahowano twarz z: {document_path}")
        print(f"Twarz zapisana w: {extracted_face}")
    else:
        print(f"Nie udało się wyekstrahować twarzy z: {document_path}")
