import cv2
import numpy as np
from PIL import Image
from mtcnn import MTCNN
import os

def extract_best_face(image_path, output_dir="extracted_faces", min_size=80):
    """
    Funkcja do wycinania najlepszej jakościowo twarzy z dokumentu tożsamości.
    
    Argumenty:
        image_path (str): Ścieżka do obrazu z dokumentem
        output_dir (str): Katalog, w którym zostaną zapisane wycięte twarze
        min_size (int): Minimalny rozmiar twarzy do detekcji
        
    Zwraca:
        str: Ścieżka do wyciętej twarzy o najlepszej jakości lub None, jeśli nie znaleziono
    """
    # Utworzenie folderu na wycięte twarze, jeśli nie istnieje
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # Wczytanie obrazu za pomocą OpenCV i konwersja z BGR do RGB
    img = cv2.imread(image_path)
    if img is None:
        print(f"Nie można wczytać obrazu: {image_path}")
        return None
    
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # Inicjalizacja detektora MTCNN
    detector = MTCNN(min_face_size=min_size)
    
    # Detekcja twarzy - używamy parametru z mniejszą czułością, aby przyspieszyć
    # i zwiększyć dokładność dla dokumentów tożsamości
    faces = detector.detect_faces(img_rgb)
    
    if not faces:
        print(f"Nie znaleziono twarzy w obrazie: {image_path}")
        return None
    
    # Ocena jakości każdej twarzy - zoptymalizowana dla dokumentów tożsamości
    best_face = None
    best_score = -1
    
    for face in faces:
        # Pobierz współrzędne i wymiary twarzy
        x, y, width, height = face['box']
        confidence = face['confidence']
        
        # Wagi kryteriów jakości dla dokumentów tożsamości:
        # 1. Rozmiar twarzy (większy = lepszy)
        size_score = width * height
        
        # 2. Pewność detekcji
        conf_score = confidence
        
        # 3. Ocena ostrości (wyższa = ostrzejsze)
        face_img = img_rgb[y:y+height, x:x+width]
        if face_img.size == 0:  # Sprawdzenie czy wycięty fragment nie jest pusty
            continue
            
        gray_face = cv2.cvtColor(face_img, cv2.COLOR_RGB2GRAY)
        laplacian_var = cv2.Laplacian(gray_face, cv2.CV_64F).var()
        
        # Całkowita ocena jakości - dostosowana do dokumentów tożsamości
        # Usunięto komponent pozycji, zwiększono wagę ostrości i pewności detekcji
        quality_score = (
            0.3 * size_score / (img.shape[0] * img.shape[1]) +  # Znormalizowany rozmiar
            0.4 * conf_score +                                  # Pewność detekcji
            0.3 * min(1.0, laplacian_var / 500)                 # Znormalizowana ostrość
        )
        
        # Sprawdź, czy to najlepsza twarz do tej pory
        if quality_score > best_score and width > min_size and height > min_size:
            best_score = quality_score
            best_face = {'box': face['box'], 'keypoints': face['keypoints'], 'score': quality_score}
    
    if best_face is None:
        print(f"Nie znaleziono odpowiedniej twarzy w obrazie: {image_path}")
        return None
    
    # Wytnij najlepszą twarz
    x, y, width, height = best_face['box']
    
    # Dodaj margines (15% z każdej strony - mniejszy dla dokumentów tożsamości)
    margin_x = int(width * 0.15)
    margin_y = int(height * 0.15)
    
    # Zapewnij, że wymiary nie wychodzą poza granice obrazu
    start_x = max(0, x - margin_x)
    start_y = max(0, y - margin_y)
    end_x = min(img.shape[1], x + width + margin_x)
    end_y = min(img.shape[0], y + height + margin_y)
    
    face_img = img_rgb[start_y:end_y, start_x:end_x]
    pil_face = Image.fromarray(face_img)
    
    # Zapisz wyciętą twarz
    base_filename = os.path.basename(image_path)
    filename, ext = os.path.splitext(base_filename)
    output_path = os.path.join(output_dir, f"{filename}_face{ext}")
    pil_face.save(output_path)
    
    print(f"Najlepsza twarz została zapisana w: {output_path}")
    print(f"Ocena jakości: {best_face['score']:.4f}")
    
    return output_path

def batch_extract_faces(input_dir, output_dir="extracted_faces", min_face_size=80):
    """
    Przetwarza wszystkie pliki JPEG w podanym katalogu.
    
    Argumenty:
        input_dir (str): Katalog z dokumentami JPEG
        output_dir (str): Katalog do zapisania wyciętych twarzy
        min_face_size (int): Minimalny rozmiar twarzy do detekcji
    """
    if not os.path.exists(input_dir):
        print(f"Katalog wejściowy nie istnieje: {input_dir}")
        return
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # Znajdź wszystkie pliki JPEG w katalogu
    image_extensions = ['.jpg', '.jpeg', '.JPG', '.JPEG']
    image_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) 
                  if os.path.isfile(os.path.join(input_dir, f)) and 
                  any(f.endswith(ext) for ext in image_extensions)]
    
    if not image_files:
        print(f"Nie znaleziono plików JPEG w katalogu: {input_dir}")
        return
    
    # Przetwarzaj każdy obraz
    results = []
    for image_path in image_files:
        print(f"Przetwarzanie obrazu: {image_path}")
        face_path = extract_best_face(image_path, output_dir, min_face_size)
        if face_path:
            results.append((image_path, face_path))
    
    print(f"Zakończono przetwarzanie. Przetworzono {len(results)} z {len(image_files)} obrazów.")
    return results

# Funkcja do optymalizacji wstępnej obrazu, aby przyspieszyć detekcję
def preprocess_image_for_id_documents(image_path, max_size=1200):
    """
    Optymalizuje obraz pod kątem detekcji twarzy na dokumentach tożsamości.
    
    Argumenty:
        image_path (str): Ścieżka do obrazu
        max_size (int): Maksymalny wymiar obrazu po skalowaniu
    
    Zwraca:
        numpy.ndarray: Zoptymalizowany obraz
    """
    img = cv2.imread(image_path)
    if img is None:
        return None
        
    # Skalowanie obrazu, jeśli jest zbyt duży
    height, width = img.shape[:2]
    if max(height, width) > max_size:
        scale = max_size / max(height, width)
        img = cv2.resize(img, (int(width * scale), int(height * scale)))
        
    # Zwiększenie kontrastu dla lepszej detekcji twarzy
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    enhanced_lab = cv2.merge((cl, a, b))
    enhanced_img = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)
    
    return enhanced_img

# Kompletna funkcja łącząca preprocessing i ekstrakcję twarzy
def extract_face_from_id_document(image_path, output_dir="extracted_faces", min_face_size=80):
    """
    Kompletna funkcja do wycinania twarzy z dokumentów tożsamości z wstępnym przetwarzaniem.
    
    Argumenty:
        image_path (str): Ścieżka do obrazu dokumentu
        output_dir (str): Katalog wyjściowy
        min_face_size (int): Minimalny rozmiar twarzy
    
    Zwraca:
        str: Ścieżka do wyciętej twarzy
    """
    # Tymczasowy plik dla przetworzonego obrazu
    temp_dir = os.path.join(output_dir, "temp")
    if not os.path.exists(temp_dir):
        os.makedirs(temp_dir)
    
    base_filename = os.path.basename(image_path)
    temp_path = os.path.join(temp_dir, f"preprocessed_{base_filename}")
    
    # Wstępne przetwarzanie
    enhanced_img = preprocess_image_for_id_documents(image_path)
    if enhanced_img is None:
        print(f"Nie można przetworzyć obrazu: {image_path}")
        return None
    
    cv2.imwrite(temp_path, enhanced_img)
    
    # Ekstrakcja twarzy
    face_path = extract_best_face(temp_path, output_dir, min_face_size)
    
    # Usunięcie tymczasowego pliku
    if os.path.exists(temp_path):
        os.remove(temp_path)
    
    return face_path

# Przykład użycia
if __name__ == "__main__":
    # Dla pojedynczego dokumentu tożsamości
    # extract_face_from_id_document("ścieżka/do/dokumentu.jpg")
    
    # Dla całego katalogu z dokumentami
    # batch_extract_faces("ścieżka/do/katalogu_z_dokumentami", "ścieżka/do/katalogu_wynikowego")
    
    # Przykładowe wywołanie
    document_path = "example_id.jpg"
    extracted_face = extract_face_from_id_document(document_path)
    
    if extracted_face:
        print(f"Pomyślnie wyekstrahowano twarz z: {document_path}")
        print(f"Twarz zapisana w: {extracted_face}")
    else:
        print(f"Nie udało się wyekstrahować twarzy z: {document_path}")

        
